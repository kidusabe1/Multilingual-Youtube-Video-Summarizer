This repo will teach you how to:
- Use LLM local or API via Ollama and again via LangChain
- Use Llama 3-8B model
- Build UI with Gradio
- Use case = "Summarize YouTube video using Llama 3"

## Run it
Assuming you have the right python environment and other required tools. You can simply run:
```shell
python main.py
```

## Tools you will use
- Ollama to run local LLM API
- `Llama 3` from Meta, to use as AI brain
- `Gradio`, to build UI
- `pytube` a python library for working with YouTube
- `LangChain` as framework for LLM app
- `tiktoken` library to estimate token counts

## Requirements
- For using this notebook smoothly, we recommend create a python environment based on our provided `requirements.txt`. <br>This can be done by
```shell
pip install -r requirements.txt
```
